This paper investigates the benefits of the side information on the universal compression of sequences from a mixture of K parametric sources. The output sequence of the mixture source is chosen from the source i \in \{1,\ldots ,K\} with a d_i-dimensional parameter vector at random according to probability vector \mathbf{w} = (w_1,\ldots,w_K). The average minimax redundancy of the universal compression of a new random sequence of length n is derived when the encoder and the decoder have a common side information of T sequences generated independently by the mixture source. Necessary and sufficient conditions on the distribution \mathbf{w} and the mixture parameter dimensions \mathbf{d} = (d_1,\ldots,d_K) are determined such that the side information provided by the previous sequences results in a reduction in the first-order term of the average codeword length compared with the universal compression without side information. Further, it is proved that the optimal compression with side information corresponds to the clustering of the side information sequences from the mixture source. Then, a clustering technique is presented to better utilize the side information by classifying the data sequences from a mixture source. Finally, the performance of the clustering on the universal compression with side information is validated using computer simulations on real network data traces.