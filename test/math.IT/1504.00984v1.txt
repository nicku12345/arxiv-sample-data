We consider a linear regression y=X\beta+u where X\in\mathbb{\mathbb{{R}}}^{n\times p}, p\gg n, and \beta is s-sparse. Motivated by examples in financial and economic data, we consider the situation where X has highly correlated and clustered columns. To perform sparse recovery in this setting, we introduce the \emph{clustering removal algorithm} (CRA), that seeks to decrease the correlation in X by removing the cluster structure without changing the parameter vector \beta. We show that as long as certain assumptions hold about X, the decorrelated matrix will satisfy the restricted isometry property (RIP) with high probability. We also provide examples of the empirical performance of CRA and compare it with other sparse recovery techniques.