In this article, we study a notion of the extraction rate of Turing functionals that translate between notions of randomness with respect to different underlying probability measures. We analyze several classes of extraction procedures: a first class that generalizes von Neumann's trick for extracting unbiased randomness from the tosses of a biased coin, a second class based on work of generating biased randomness from unbiased randomness by Knuth and Yao, and a third class independently developed by Levin and Kautz that generalizes the data compression technique of arithmetic coding. For the first two classes of extraction procedures, we identify a level of algorithmic randomness for an input that guarantees that we attain the extraction rate along that input, while for the third class, we calculate the rate attained along sufficiently random input sequences.