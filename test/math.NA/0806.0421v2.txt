The authors show that the round-off error can break the consistency which is the premise of using the difference equation to replace the original differential equations. We therefore proposed a theoretical approach to investigate this effect, and found that the difference scheme can not guarantee the convergence of the actual compute result to the analytical one. A conservation scheme experiment is applied to solve a simple linear differential equation satisfing the LAX equivalence theorem in a finite precision computer. The result of this experiment is not convergent when time step-size decreases trend to zero, which proves that even the stable scheme can't guarantee the numerical convergence in finite precision computer. Further the relative convergence concept is introduced.