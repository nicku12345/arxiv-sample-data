The Koopman operator is a linear, infinite-dimensional operator that governs the dynamics of system observables; Extended Dynamic Mode Decomposition (EDMD) is a data-driven method for approximating the Koopman operator using functions (features) of the system state snapshots. This paper investigates an approach to EDMD in which the features used provide random approximations to a particular kernel function. The objective of this is computational economy for large data sets: EDMD is generally ill-suited for problems with large state dimension, and its dual kernel formulation (KDMD) is well-suited for such problems only if the number of data snapshots is relatively small. We discuss two specific methods for generating features: random Fourier features, and the Nystrom method. The first method is a data-independent method for translation-invariant kernels only and involves random sampling in feature space; the second method is a data-dependent empirical method that may be used for any kernel and involves random sampling of data. We first discuss how these ideas may be applied in an EDMD context, as well as a means for adaptively adding random Fourier features. We demonstrate these methods on two example problems and conclude with an analysis of the relative benefits and drawbacks of each method.