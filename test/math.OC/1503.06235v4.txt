This paper studies the convergence time of dual gradient methods for general (possibly non-differentiable) strongly convex programs. For general convex programs, the convergence time of dual subgradient/gradient methods with simple running averages (running averages started from iteration 0) is known to be O(\frac{1}{\epsilon^{2}}). This paper shows that the convergence time for general strongly convex programs is O(\frac{1}{\epsilon}). This paper also considers a variation of the average scheme, called the sliding running averages, and shows that if the dual function of the strongly convex program is locally quadratic (Note that the locally quadratic property is implied by the locally strongly concave property.) then the convergence time of the dual gradient method with sliding running averages is O(\log(\frac{1}{\epsilon})). The convergence time analysis is further verified by numerical experiments.