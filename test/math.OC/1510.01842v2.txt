Given all (finite) moments of two measures \mu and \lambda on \R^n, we provide a numerical scheme to obtain the Lebesgue decomposition \mu=\nu+\psi with \nu\ll\lambda and \psi\perp\lambda. When\nu has a density in L\_\infty(\lambda) then we obtain two sequences of finite moments vectorsof increasing size (the number of moments) which converge to the moments of \nu and \psi respectively, as the number of moments increases. Importantly, {\it no} \`a priori knowledge on the supports of \mu, \nu and \psi is required.