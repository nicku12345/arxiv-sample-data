We study the maximum achievable differential entropy at the output of a system assigning to each input X the sum X+N, with N a given noise with probability law absolutely continuous with respect to the Lebesgue measure and where the input and the noise are allowed to be dependent. We consider fairly general average cost constraints in the input, as well as amplitude constraints. It is shown that the corresponding search for the optimum may be performed over joint distributions for the input and the noise concentrated in lower dimensional geometrical objects represented by graphs of sufficiently regular functions in the associated noise-input plane. The results are then applied to correspondingly characterize the independent input and noise case, so providing bounds for channel capacity. Analysis of achievable bounds and associated capacity-achieving input distributions is also provided. General conditions for the existence of a maximum achievable entropy at the output are provided for such a system, as well as for the independent input and noise case, so establishing conditions for capacity to be achievable. The laws of such capacity-achieving input distributions are also uniquely specified. A general approximation to capacity scheme is also provided, showing that in the not achievable case the corresponding noise can be written as the limit of a sequence of noise random variables with associated channels being capacity achievable, and whose capacities converge to the capacity of the original channel. The relationship between our results for this input and noise dependent setting and the notion of feedback capacity are also explored.