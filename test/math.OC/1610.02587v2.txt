In this paper, we are concerned with a stochastic optimal control problem of mean-field type under partial observation, where the state equation is governed by the controlled nonlinear mean-field stochastic differential equation, moreover the observation noise is allowed to enter into the state equation and the observation coefficients may depend not only on the control process and but also on its probability distribution. Under standard assumptions on the coefficients, by dual analysis and convex variation, we establish the maximum principle for optimal control in a strong sense as well as a weak one, respectively. As an application, a partially observed linear quadratic control problem of mean-field type is studied detailed and the corresponding dual characterization and state feedback presentation of the partially observed optimal control are obtained by the stochastic maximum principles and the classic technique of completing squares.