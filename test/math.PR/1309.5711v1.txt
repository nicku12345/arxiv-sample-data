Let \mathbf X be a random matrix whose pairs of entries X_{jk} and X_{kj} are correlated and vectors  (X_{jk},X_{kj}), for 1\le j<k\le n, are mutually independent. Assume that the diagonal entries are independent from off-diagonal entries as well. We assume that \mathbb{E} X_{jk}=0, \mathbb{E} X_{jk}^2=1, for any j,k=1,\ldots,n and \mathbb{E} X_{jk}X_{kj}=\rho for 1\le j<k\le n. Let \mathbf M_n be a non-random n\times n matrix with \|\mathbf M_n\|\le Kn^Q, for some positive constants K>0 and Q\ge 0. Let s_n(\mathbf X+\mathbf M_n) denote the least singular value of the matrix \mathbf X+\mathbf M_n. It is shown that there exist positive constants A and B depending on K,Q,\rho only such that  \mathbb{P}(s_n(\mathbf X+\mathbf M_n)\le n^{-A})\le n^{-B}.  As an application of this result we prove the elliptic law for this class of matrices with non identically distributed correlated entries.