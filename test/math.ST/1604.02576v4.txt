In this paper, we further develop the approach, originating in [GJN], to "computation-friendly" hypothesis testing via Convex Programming. Most of the existing results on hypothesis testing aim to quantify in a closed analytic form separation between sets of distributions allowing for reliable decision in precisely stated observation models. In contrast to this descriptive (and highly instructive) traditional framework, the approach we promote here can be qualified as operational -- the testing routines and their risks are yielded by an efficient computation. All we know in advance is that, under favorable circumstances, specified in [GJN], the risk of such test, whether high or low, is provably near-optimal under the circumstances. As a compensation for the lack of "explanatory power," this approach is applicable to a much wider family of observation schemes and hypotheses to be tested than those where "closed form descriptive analysis" is possible.   In the present paper our primary emphasis is on computation: we make a step further in extending the principal tool developed in the cited paper -- testing routines based on affine detectors -- to a large variety of testing problems. The price of this development is the loss of blanket near-optimality of the proposed procedures (though it is still preserved in the observation schemes studied in [GJN], which now become particular cases of the general setting considered here).   [GJN]: Goldenshluger, A., Juditsky, A., Nemirovski, A. "Hypothesis testing by convex optimization," Electronic Journal of Statistics 9(2), 2015