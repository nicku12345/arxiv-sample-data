We provide a new version of delta theorem, that takes into account of high dimensional parameter estimation. We show that depending on the structure of the function, the limits of functions of estimators have faster or slower rate of convergence than the limits of estimators. We illustrate this via two examples. First, we use it for testing in high dimensions, and second in estimating large portfolio risk. Our theorem works in the case of larger number of parameters, p, than the sample size, n: p>n.