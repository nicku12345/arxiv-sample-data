A novel framework for the analysis of observation statistics on time discrete linear evolutions in Banach space is presented. The model differs from traditional models for stochastic processes and, in particular, clearly distinguishes between the deterministic evolution of a system and the stochastic nature of observations on the evolving system. General Markov chains are defined in this context and it is shown how typical traditional models of classical or quantum random walks and Markov processes fit into the framework and how a theory of quantum statistics ({\it sensu} Barndorff-Nielsen, Gill and Jupp) may be developed from it. The framework permits a general theory of joint observability of two or more observation variables which may be viewed as an extension of the Heisenberg uncertainty principle and, in particular, offers a novel mathematical perspective on the violation of Bell's inequalities in quantum models. Main results include a general sampling theorem relative to Riesz evolution operators in the spirit of von Neumann's mean ergodic theorem for normal operators in Hilbert space.