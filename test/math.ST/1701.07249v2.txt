Let {\bf R} be the Pearson correlation matrix of m normal random variables. The Rao's score test for the independence hypothesis H_0 : {\bf R} = {\bf I}_m, where {\bf I}_m is the identity matrix of dimension m, was first considered by Schott (2005) in the high dimensional setting. In this paper, we study the asymptotic minimax power function of this test, under an asymptotic regime in which both m and the sample size n tend to infinity with the ratio m/n upper bounded by a constant. In particular, our result implies that the Rao's score test is rate-optimal for detecting the dependency signal \|{\bf R} - {\bf I}_m\|_F of order \sqrt{m/n}, where \|\cdot\|_F is the matrix Frobenius norm.