We study the problem of nonparametric estimation under \bL_p-loss, p\in [1,\infty), in the framework of the convolution structure density model on \bR^d. This observation scheme is a generalization of two classical statistical models, namely density estimation under direct and indirect observations. In Part I the original pointwise selection rule from a family of "kernel-type" estimators is proposed. For the selected estimator, we prove an \bL_p-norm oracle inequality and several of its consequences. In Part II the problem of adaptive minimax estimation under \bL_p--loss over the scale of anisotropic Nikol'skii classes is addressed. We fully characterize the behavior of the minimax risk for different relationships between regularity parameters and norm indexes in the definitions of the functional class and of the risk. We prove that the selection rule proposed in Part I leads to the construction of an optimally or nearly optimally (up to logarithmic factor) adaptive estimator.