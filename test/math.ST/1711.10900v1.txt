Asymptotic statistical theory for estimating functions is reviewed in a generality suitable for stochastic processes. Conditions concerning existence of a consistent estimator, uniqueness, rate of convergence, and the asymptotic distribution are treated separately. Our conditions are not minimal, but can be verified for many interesting stochastic process models. Several examples illustrate the wide applicability of the theory and why the generality is needed.