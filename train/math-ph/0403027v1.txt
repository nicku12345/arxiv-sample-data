Contraction theory is a recently developed dynamic analysis and nonlinear control system design tool based on an exact differential analysis of convergence. This paper extends contraction theory to local and global stability analysis of important classes of nonlinear distributed dynamics, such as convection-diffusion-reaction processes, Lagrangian and Hamilton-Jacobi dynamics, and optimal controllers and observers. The Hamilton-Jacobi-Bellman controller and a similar optimal nonlinear observer design are studied. Explicit stability conditions are given, which extend the well-known conditions on controllability and observability Grammians for linear time-varying systems. Stability of the Hamilton-Jacobi dynamics is assessed by evaluating the Hessian of the system state along system trajectories. In contrast to stability proofs based on energy dissipation,this principle allows to conclude on stability of energy-based systems that are excited by time-varying inputs. In this context, contraction can be regarded as describing new variational conservation laws and the stability of entropy producing processes.