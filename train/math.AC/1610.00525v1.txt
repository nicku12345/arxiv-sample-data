Let (R,\m,k) be a Noetherian local ring with maximal ideal \m and residue field k. The linearity defect of a finitely generated R-module M, which is denoted \ld_R(M), is a numerical measure of how far M is from having linear resolution. We study the linearity defect of the residue field. We give a positive answer to the question raised by Herzog and Iyengar of whether \ld_R(k)<\infty implies \ld_R(k)=0, in the case when \m^4=0.