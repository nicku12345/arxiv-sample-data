Existence of oblique polar lines for the meromorphic extension of the current valued function \int |f|^{2\lambda}|g|^{2\mu}\square is given under the following hypotheses: f and g are holomorphic function germs in \CC^{n+1} such that g is non-singular, the germ S:=\ens{\d f\wedge \d g =0} is one dimensional, and g|_S is proper and finite. The main tools we use are interaction of strata for f (see \cite{B:91}), monodromy of the local system H^{n-1}(u) on S for a given eigenvalue \exp(-2i\pi u) of the monodromy of f, and the monodromy of the cover g|_S. Two non-trivial examples are completely worked out.