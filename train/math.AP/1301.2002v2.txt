The aim of this paper is to contribute to the understanding of the pattern formation phenomenon in reaction-diffusion equations coupled with ordinary differential equations. Such systems of equations arise, for example, from modeling of interactions between cellular processes such as cell growth, differentiation or transformation and diffusing signaling factors. We focus on stability analysis of solutions of a prototype model consisting of a single reaction-diffusion equation coupled to an ordinary differential equation. We show that such systems are very different from classical reaction-diffusion models. They exhibit diffusion-driven instability (Turing instability) under a condition of autocatalysis of non-diffusing component. However, the same mechanism which destabilizes constant solutions of such models, destabilizes also all continuous spatially heterogeneous stationary solutions, and consequently, there exist no stable Turing patterns in such reaction-diffusion-ODE systems. We provide a rigorous result on the nonlinear instability, which involves the analysis of a continuous spectrum of a linear operator induced by the lack of diffusion in the destabilizing equation. These results are extended to discontinuous patterns for a class of nonlinearities.