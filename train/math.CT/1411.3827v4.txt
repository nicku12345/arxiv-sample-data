We show that contrary to common belief in the DisCoCat community, a monoidal category is all that is needed to define a categorical compositional model of natural language. This relies on a construction which freely adds adjoints to a monoidal category. In the case of distributional semantics, this broadens the range of available models, to include non-linear maps and cartesian products for instance. We illustrate the applications of this principle to various distributional models of meaning.