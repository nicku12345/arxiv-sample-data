In this paper, we present some results on information, complexity and entropy as defined below and we discuss their relations with the Kolmogorov-Sinai entropy which is the most important invariant of a dynamical system. These results have the following features and motivations:   -we give a new computable definition of information and complexity which allows to give a computable characterization of the K-S entropy;   -these definitions make sense even for a single orbit and can be measured by suitable data compression algorithms; hence they can be used in simulations and in the analysis of experimental data;   -the asymptotic behavior of these quantities allows to compute not only the Kolmogorov-Sinai entropy but also other quantities which give a measure of the chaotic behavior of a dynamical system even in the case of null entropy.