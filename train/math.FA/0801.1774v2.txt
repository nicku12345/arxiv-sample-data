This paper addresses the regularization by sparsity constraints by means of weighted \ell^p penalties for 0\leq p\leq 2. For 1\leq p\leq 2 special attention is payed to convergence rates in norm and to source conditions. As main result it is proven that one gets a convergence rate in norm of \sqrt{\delta} for 1\leq p\leq 2 as soon as the unknown solution is sparse. The case p=1 needs a special technique where not only Bregman distances but also a so-called Bregman-Taylor distance has to be employed.   For p<1 only preliminary results are shown. These results indicate that, different from p\geq 1, the regularizing properties depend on the interplay of the operator and the basis of sparsity. A counterexample for p=0 shows that regularization need not to happen.