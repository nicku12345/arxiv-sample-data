We study the asymptotic behavior of a bounded solution of an inhomogeneous delay linear difference equation in a Banach space by using the spectrum of bounded sequences. We get a significant extension of excellent results in [1]. A new simple proof is also found for the famous Gelfand spectral radius theorem. Moreover, among other things we prove that if the spectrum of a bounded sequence \{x_n\}_n is finite then x_n=c_1\vartheta_1^n+c_2\vartheta_2^n+\cdots+c_k\vartheta_k^n+o(1) as n\to\infty where |\vartheta_1|=|\vartheta_2|=\cdots=|\vartheta_k|=1.