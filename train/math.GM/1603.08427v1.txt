Square roots of probabilities appear in several contexts, which suggests that they are somehow more fundamental than probabilities. Square roots of probabilities appear in expressions of the Fisher-Rao Metric and the Hellinger-Bhattacharyya distance. They also come into play in Quantum Mechanics via the Born rule where probabilities are found by taking the squared modulus of the quantum amplitude. Why should this be the case and why do these square roots not arise in the various formulations of probability theory?   In this short, inconclusive exploration, I consider quantifying a logical statement with a vector defined by a set of components each quantifying one of the atomic statements defining the hypothesis space. I show that conditional probabilities (bi-valuations), such as P(x|y), can be written as the dot product of the two vectors quantifying the logical statements x and y each normalized with respect to the vector quantifying the conditional y. The components of the vectors are proportional to the square root of the probability. As a result, this formulation is shown to be consistent with a concept of orthogonality applied to the set of mutually exclusive atomic statements such that the sum rule is represented as the sum of the squares of the square roots of probability.