Let \mathbf{L} be the set of all normal and convex functions from {[0, 1]} to {[0, 1]}. This paper proves that {t}-norm in the sense of Walker-and-Walker is strictly stronger that {t_r}-norm on \mathbf{L}, which is strictly stronger than {t}-norm on \mathbf{L}. Furthermore, let {\curlywedge} and {\curlyvee} be special convolution operations defined by  {(f\curlywedge g)(x)=\sup\left\{f(y)\star g(z): y\vartriangle z=x\right\},}   {(f\curlyvee g)(x)=\sup\left\{f(y)\star g(z): y\ \triangledown\ z=x\right\},}  for {f, g\in Map([0, 1], [0, 1])}, where {\vartriangle} and {\triangledown} are respectively a {t}-norm and a {t}-conorm on {[0, 1]} (not necessarily continuous), and {\star} is a binary operation on {[0, 1]}. Then, it is proved that if the binary operation {\curlywedge} is a {t_r}-norm (resp., {\curlyvee} is a {t_r}-conorm), then {\vartriangle} is a continuous {t}-norm (resp., {\triangledown} is a continuous {t}-conorm) on {[0, 1]}, and {\star} is a {t}-norm on {[0, 1]}.