We show that a real sequence x is convergent if and only if there exist a regular matrix A and an F_{\sigma\delta}-ideal \mathcal{I} on \mathbf{N} such that the set of subsequences y of x for which Ay is \mathcal{I}-convergent is of the second Baire category. This includes the cases where \mathcal{I} is the ideal of asymptotic density zero sets, the ideal of Banach density zero sets, and the ideal of finite sets. The latter recovers an old result given by Keogh and Petersen in [J. London Math. Soc. \textbf{33} (1958), 121--123]. Our proofs are of a different nature and rely on recent results in the context of \mathcal{I}-Baire classes and filter games.   As application, we obtain a stronger version of the classical Steinhaus' theorem: for each regular matrix A, there exists a \{0,1\}-valued sequence x such that Ax is not statistically convergent.