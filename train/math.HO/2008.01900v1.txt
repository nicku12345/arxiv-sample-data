This paper gives a personal assessment of Epoch making advances in Matrix Computations from antiquity and with an eye towards tomorrow.   We trace the development of number systems and elementary algebra, and the uses of Gaussian Elimination methods from around 2000 BC on to current real-time Neural Network computations to solve time-varying linear equations.   We include relevant advances from China from the 3rd century AD on, and from India and Persia in the 9th century and discuss the conceptual genesis of vectors and matrices in central Europe and Japan in the 14th through 17th centuries AD.   Followed by the 150 year cul-de-sac of polynomial root finder research for matrix eigenvalues, as well as the superbly useful matrix iterative methods and Francis' eigenvalue Algorithm from last century.   Then we explain the recent use of initial value problem solvers to master time-varying linear and nonlinear matrix equations via Neural Networks.   We end with a short outlook upon new hardware schemes with multilevel processors that go beyond the 0-1 base 2 framework which all of our past and current electronic computers have been using.