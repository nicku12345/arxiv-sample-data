The feedback capacity of the stationary Gaussian additive noise channel has been open, except for the case where the noise is white. Here we find the feedback capacity of the stationary first-order moving average additive Gaussian noise channel in closed form. Specifically, the channel is given by Y_i = X_i + Z_i, i = 1, 2, ..., where the input \{X_i\} satisfies a power constraint and the noise \{Z_i\} is a first-order moving average Gaussian process defined by Z_i = \alpha U_{i-1} + U_i, |\alpha| \le 1, with white Gaussian innovations U_i, i = 0,1,....   We show that the feedback capacity of this channel is -\log x_0, where x_0 is the unique positive root of the equation  \rho x^2 = (1-x^2) (1 - |\alpha|x)^2, and \rho is the ratio of the average input power per transmission to the variance of the noise innovation U_i. The optimal coding scheme parallels the simple linear signalling scheme by Schalkwijk and Kailath for the additive white Gaussian noise channel -- the transmitter sends a real-valued information-bearing signal at the beginning of communication and subsequently refines the receiver's error by processing the feedback noise signal through a linear stationary first-order autoregressive filter. The resulting error probability of the maximum likelihood decoding decays doubly-exponentially in the duration of the communication. This feedback capacity of the first-order moving average Gaussian channel is very similar in form to the best known achievable rate for the first-order \emph{autoregressive} Gaussian noise channel studied by Butman, Wolfowitz, and Tiernan, although the optimality of the latter is yet to be established.