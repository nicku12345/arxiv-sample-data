The decoding error probability of codes is studied as a function of their block length. It is shown that the existence of codes with a polynomially small decoding error probability implies the existence of codes with an exponentially small decoding error probability. Specifically, it is assumed that there exists a family of codes of length N and rate R=(1-\epsilon)C (C is a capacity of a binary symmetric channel), whose decoding probability decreases polynomially in 1/N. It is shown that if the decoding probability decreases sufficiently fast, but still only polynomially fast in 1/N, then there exists another such family of codes whose decoding error probability decreases exponentially fast in N. Moreover, if the decoding time complexity of the assumed family of codes is polynomial in N and 1/\epsilon, then the decoding time complexity of the presented family is linear in N and polynomial in 1/\epsilon. These codes are compared to the recently presented codes of Barg and Zemor, ``Error Exponents of Expander Codes,'' IEEE Trans. Inform. Theory, 2002, and ``Concatenated Codes: Serial and Parallel,'' IEEE Trans. Inform. Theory, 2005. It is shown that the latter families can not be tuned to have exponentially decaying (in N) error probability, and at the same time to have decoding time complexity linear in N and polynomial in 1/\epsilon.