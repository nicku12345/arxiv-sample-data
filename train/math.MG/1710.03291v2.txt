Given x\in(0, 1], let \mathcal U(x) be the set of bases q\in(1,2] for which there exists a unique sequence (d_i) of zeros and ones such that x=\sum_{i=1}^\infty d_i/q^i. L\"{u}, Tan and Wu (2014) proved that \mathcal U(x) is a Lebesgue null set of full Hausdorff dimension. In this paper, we show that the algebraic sum \mathcal U(x)+\lambda\mathcal U(x) and product \mathcal U(x)\cdot\mathcal U(x)^\lambda contain an interval for all x\in(0, 1] and \lambda\ne 0. As an application we show that the same phenomenon occurs for the set of non-matching parameters studied by the first author and Kalle (2017).