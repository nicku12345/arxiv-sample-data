We consider the Dirac equation in \R^3 with constant coefficients and study the distribution \mu_t of the random solution at time t\in\R. It is assumed that the initial measure \mu_0 has zero mean, a translation-invariant covariance, and finite mean charge density. We also assume that \mu_0 satisfies a mixing condition of Rosenblatt- or Ibragimov-Linnik-type. The main result is the convergence of \mu_t to a Gaussian measure as t\to\infty. The proof uses the study of long time asymptotics of the solution and S.N. Bernstein's ``room-corridor'' method.