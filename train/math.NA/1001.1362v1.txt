A preconditioning theory is presented which establishes sufficient conditions for multiplicative and additive Schwarz algorithms to yield self-adjoint positive definite preconditioners. It allows for the analysis and use of non-variational and non-convergent linear methods as preconditioners for conjugate gradient methods, and it is applied to domain decomposition and multigrid. It is illustrated why symmetrizing may be a bad idea for linear methods. It is conjectured that enforcing minimal symmetry achieves the best results when combined with conjugate gradient acceleration. Also, it is shown that absence of symmetry in the linear preconditioner is advantageous when the linear method is accelerated by using the Bi-CGstab method. Numerical examples are presented for two test problems which illustrate the theory and conjectures.