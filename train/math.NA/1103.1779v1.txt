We provide a comparative study of the Subspace Projected Approximate Matrix method, abbreviated SPAM, which is a fairly recent iterative method to compute a few eigenvalues of a Hermitian matrix A. It falls in the category of inner-outer iteration methods and aims to save on the costs of matrix-vector products with A within its inner iteration. This is done by choosing an approximation A_0 of A, and then, based on both A and A_0, to define a sequence (A_k)_{k=0}^n of matrices that increasingly better approximate A as the process progresses. Then the matrix A_k is used in the kth inner iteration instead of A.   In spite of its main idea being refreshingly new and interesting, SPAM has not yet been studied in detail by the numerical linear algebra community. We would like to change this by explaining the method, and to show that for certain special choices for A_0, SPAM turns out to be mathematically equivalent to known eigenvalue methods. More sophisticated approximations A_0 turn SPAM into a boosted version of Lanczos, whereas it can also be interpreted as an attempt to enhance a certain instance of the preconditioned Jacobi-Davidson method.   Numerical experiments are performed that are specifically tailored to illustrate certain aspects of SPAM and its variations. For experiments that test the practical performance of SPAM in comparison with other methods, we refer to other sources. The main conclusion is that SPAM provides a natural transition between the Lanczos method and one-step preconditioned Jacobi-Davidson.