This paper investigates the least-squares projection method for bounded linear operators, which provides a natural regularization scheme by projection for many ill-posed problems. Yet, without additional assumptions, the convergence of this approximation scheme cannot be guaranteed. We reveal that the convergence of least-squares projection method is determined by two independent factors -- the kernel approximability and the offset angle. The kernel approximability is a necessary condition of convergence described with kernel N(T) and its subspaces N(T){\cap}X_n, and we give several equivalent characterizations for it (Theorem 1). The offset angle of X_n is defined as the largest canonical angle between space T^*T(X_n) and T^{\dagger}T(X_n) (which are subspaces of N(T)^\bot), and it geometrically reflects the rate of convergence (Theorem 2). The paper also presents new observations for the unconvergence examples of Seidman [10, Example 3.1] and Du [2, Example 2.10] under the notions of kernel approximability and offset angle.