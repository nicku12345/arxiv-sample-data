We introduce a new class of optimal iterative methods without memory for approximating a simple root of a given nonlinear equation. The proposed class uses four function evaluations and one first derivative evaluation per iteration and it is therefore optimal in the sense of Kung and Traub's conjecture. We present the construction, convergence analysis and numerical implementations, as well as comparisons of accuracy and basins of attraction between our method and existing optimal methods for several test problems.