This paper is concerned with the performance of Orthogonal Matching Pursuit (OMP) algorithms applied to a dictionary \mathcal{D} in a Hilbert space \mathcal{H}. Given an element f\in \mathcal{H}, OMP generates a sequence of approximations f_n, n=1,2,\dots, each of which is a linear combination of n dictionary elements chosen by a greedy criterion. It is studied whether the approximations f_n are in some sense comparable to {\em best n term approximation} from the dictionary. One important result related to this question is a theorem of Zhang \cite{TZ} in the context of sparse recovery of finite dimensional signals. This theorem shows that OMP exactly recovers n-sparse signal, whenever the dictionary \mathcal{D} satisfies a Restricted Isometry Property (RIP) of order An for some constant A, and that the procedure is also stable in \ell^2 under measurement noise. The main contribution of the present paper is to give a structurally simpler proof of Zhang's theorem, formulated in the general context of n term approximation from a dictionary in arbitrary Hilbert spaces \mathcal{H}. Namely, it is shown that OMP generates near best n term approximations under a similar RIP condition.