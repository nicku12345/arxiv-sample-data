The Radon transform is a linear integral transform that mimics the data formation process in medical imaging modalities like X-ray Computerized Tomography and Positron Emission Tomography. The Hough transform is a pattern recognition technique, which is mainly used to detect straight lines in digital images and which has been recently extended to the automatic recognition of algebraic plane curves. Although defined in very different ways, in numerical applications both transforms ultimately take an image as an input and provide, as an output, a function defined on a parameter space. The parameters in this space describe a family of curves, which represent either the integration domains considered in the (generalized) Radon transform, or the curves to be detected by means of the Hough transform. In both cases, the 2D plot of the intensity values of the output function is the so-called (Radon or Hough) sinogram. While the Hough sinogram is produced by an algorithm whose implementation requires that the parameter space be discretized in cells, the Radon sinogram is mathematically defined on a continuous parameter space, which in turn may need to be discretized just for physical or numerical reasons. In this paper, by considering a more general and n-dimensional setting, we prove that, whether the input image is described as a set of points (possibly with different intensity values) or as a piecewise constant function, its (rescaled) Hough sinogram converges to the corresponding Radon sinogram as the discretization step in the parameter space tends to zero. We also show that this result may have a notable impact on the image reconstruction problem of inverting the Radon sinogram recorded by a medical imaging scanner, and that the description of the Hough transform problem within the framework of regularization theory for inverse problems is worth investigating.