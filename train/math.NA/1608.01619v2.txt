The Total Least Squares solution of an overdetermined, approximate linear equation Ax \approx b minimizes a nonlinear function which characterizes the backward error. We show that a globally convergent variant of the Gauss--Newton iteration can be tailored to compute that solution. At each iteration, the proposed method requires the solution of an ordinary least squares problem where the matrix A is perturbed by a rank-one term.