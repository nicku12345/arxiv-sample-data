We analyze backward step control globalization for finding zeros of G\^ateaux-differentiable functions that map from a Banach space to a Hilbert space. The results include global convergence to a distinctive solution characterized by propagating the initial guess by a generalized Newton flow with guaranteed bounds on the discrete nonlinear residual norm decrease and an (also numerically) easily controllable asymptotic linear residual convergence rate. The convergence theory can be exploited to construct efficient numerical methods, which we demonstrate for the case of a Krylov-Newton method and an approximation-by-discretization multilevel framework. Both approaches optimize the asymptotic linear residual convergence rate, either over the Krylov subspace or through adaptive discretization, which in turn yields practical and efficient stopping criteria and refinement strategies that balance the nonlinear residuals with the relative residuals of the linear systems. We apply these methods to the class of nonlinear elliptic boundary value problems and present numerical results for the Carrier equation and the minimum surface equation.