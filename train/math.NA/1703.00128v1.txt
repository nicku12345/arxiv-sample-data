In this article, we present a cost-benefit analysis of the approximation in tensor products of Hilbert spaces of Sobolev-analytic type. The Sobolev part is defined on a finite dimensional domain, whereas the analytical space is defined on an infinite dimensional domain. As main mathematical tool, we use the \varepsilon-dimension of a subset in a Hilbert space. The \varepsilon-dimension gives the lowest number of linear information that is needed to approximate an element from the set in the norm of the Hilbert space up to an accuracy \varepsilon>0. From a practical point of view this means that we a priori fix an accuracy and ask for the amount of information to achieve this accuracy. Such an analysis usually requires sharp estimates on the cardinality of certain index sets which are in our case infinite-dimensional hyperbolic crosses. As main result, we obtain sharp bounds of the \varepsilon-dimension of the Sobolev-analytic-type function classes which depend only on the smoothness differences in the Sobolev spaces and the dimension of the finite dimensional domain where these spaces are defined. This implies in particular that, up to constants, the costs of the infinite dimensional (analytical) approximation problem is dominated by the finite-variate Sobolev approximation problem. We demonstrate this procedure with an examples of functions spaces stemming from the regularity theory of parametric partial differential equation.