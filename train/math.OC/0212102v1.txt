At the core of optimal control theory is the Pontryagin maximum principle - the celebrated first order necessary optimality condition - whose solutions are called extremals and which are obtained through a function called Hamiltonian, akin to the Lagrangian function used in ordinary calculus optimization problems. A remarkable property of the extremals is that the total derivative with respect to time of the corresponding Hamiltonian equals the partial derivative of the Hamiltonian with respect to time. In particular, when the Hamiltonian does not depend explicitly on time, the value of the Hamiltonian evaluated along the extremals turns out to be constant (a property that corresponds to energy conservation in classical mechanics). We present a generalization of the above property. As applications of the new relation, methods for obtaining conserved quantities along the Pontryagin extremals and for characterizing problems possessing given constants of the motion are obtained.