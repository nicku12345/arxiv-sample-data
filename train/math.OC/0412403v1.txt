We consider a class of optimal control problems of stochastic delay differential equations (SDDE) that arise in connection with optimal advertising under uncertainty for the introduction of a new product to the market, generalizing classical work of Nerlove and Arrow (1962). In particular, we deal with controlled SDDE where the delay enters both the state and the control. Following ideas of Vinter and Kwong (1981) (which however hold only in the deterministic case), we reformulate the problem as an infinite dimensional stochastic control problem to which we associate, through the dynamic programming principle, a second order Hamilton-Jacobi-Bellman equation. We show a verification theorem and we exhibit some simple cases where such equation admits an explicit smooth solution, allowing us to construct optimal feedback controls.