We consider the minimization of the number of non-zero coefficients (the \ell_0 "norm") of the representation of a data set in terms of a dictionary under a fidelity constraint. (Both the dictionary and the norm defining the constraint are arbitrary.) This (nonconvex) optimization problem naturally leads to the sparsest representations, compared with other functionals instead of the \ell_0 "norm". Our goal is to measure the sets of data yielding a K-sparse solution--i.e. involving K non-zero components. Data are assumed uniformly distributed on a domain defined by any norm--to be chosen by the user. A precise description of these sets of data is given and relevant bounds on the Lebesgue measure of these sets are derived. They naturally lead to bound the probability of getting a K-sparse solution. We also express the expectation of the number of non-zero components. We further specify these results in the case of the Euclidean norm, the dictionary being arbitrary.