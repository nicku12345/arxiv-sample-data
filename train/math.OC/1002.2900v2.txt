This paper presents an inverse optimality method to solve the Hamilton-Jacobi-Bellman equation for a class of nonlinear problems for which the cost is quadratic and the dynamics are affine in the input. The method is inverse optimal because the running cost that renders the control input optimal is also explicitly determined. One special feature of this work, as compared to other methods in the literature, is the fact that the solution is obtained directly for the control input. The value function can also be obtained after one solves for the control input. Furthermore, a Lyapunov function that proves at least local stability of the controller is also obtained. In this regard the main contribution of this paper can be interpreted in two different ways: offering an analytical expression for Lyapunov functions for a class of nonlinear systems and obtaining an optimal controller for the same class of systems using a specific optimization functional. We also believe that an additional contribution of this paper is to identify explicit classes of systems and optimization functionals for which optimal control problems can be solved analytically. In particular, for second order systems three cases are identified: i) control input only as a function of the second state variable, ii) control input affine in the second state variable when the dynamics are affine in that variable and iii) control input affine in the first state variable when the dyamics are affine in that variable. The relevance of the proposed methodology is illustrated in several examples, including the Van der Pol oscillator, mass-spring systems and vehicle path following.