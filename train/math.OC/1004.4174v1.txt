In an optimal control framework, we consider the value V_T(x) of the problem starting from state x with finite horizon T, as well as the value V_\lambda(x) of the \lambda-discounted problem starting from x. We prove that uniform convergence (on the set of states) of the values V_T(\cdot) as T tends to infinity is equivalent to uniform convergence of the values V_\lambda(\cdot) as \lambda tends to 0, and that the limits are identical. An example is also provided to show that the result does not hold for pointwise convergence. This work is an extension, using similar techniques, of a related result in a discrete-time framework \cite{LehSys}.