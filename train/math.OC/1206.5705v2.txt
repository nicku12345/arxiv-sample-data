The notion of quasi-Fej\'er monotonicity has proven to be an efficient tool to simplify and unify the convergence analysis of various algorithms arising in applied nonlinear analysis. In this paper, we extend this notion in the context of variable metric algorithms, whereby the underlying norm is allowed to vary at each iteration. Applications to convex optimization and inverse problems are demonstrated.