A new approach to solving a large class of factorable nonlinear programming (NLP) problems to global optimality is presented in this paper. Unlike the traditional strategy of partitioning the decision-variable space employed in many branch-and-bound methods, the proposed approach approximates the NLP problem by a reverse-convex programming (RCP) problem to a controlled precision, with the latter then solved by an enumerative search. To establish the theoretical guarantees of the method, the notion of "RCP regularity" is introduced and it is proven that enumeration is guaranteed to yield a global optimum when the RCP problem is regular. An extended RCP algorithmic framework is then presented and its performance is examined for a small set of test problems.