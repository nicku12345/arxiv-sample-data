We introduce a modification of Perron's method, where semi-solutions are considered in a carefully defined asymptotic sense. With this definition, we can show, in a rather elementary way, that in a zero-sum game or a control problem (with or without model uncertainty), the value function over all strategies coincides with the value function over Markov strategies discretized in time. Therefore, there are always discretized Markov \varepsilon-optimal strategies, (uniform with respect to the bounded initial condition). With a minor modification, the method produces a value and approximate saddle points for an asymmetric game of feedback strategies vs. counter-strategies.