We present an optimization framework for solving multi-agent nonlinear programs subject to inequality constraints while keeping the agents' state trajectories private. Each agent has an objective function depending only upon its own state and the agents are collectively subject to global constraints. The agents do not directly communicate with each other but instead route messages through a trusted cloud computer. The cloud computer adds noise to data being sent to the agents in accordance with the framework of differential privacy in order to keep each agent's state trajectory private from all other agents and any eavesdroppers. This private problem can be viewed as a stochastic variational inequality and is solved using a projection-based method for solving variational inequalities that resembles a noisy primal-dual gradient algorithm. Convergence of the optimization algorithm in the presence of noise is proven and a quantifiable trade-off between privacy and convergence is extracted from this proof. Simulation results are provided that demonstrate numerical convergence for both \epsilon-differential privacy and (\epsilon, \delta)-differential privacy.