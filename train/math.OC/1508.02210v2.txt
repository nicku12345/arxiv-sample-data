This work aims to explore the regularity properties of the smoothed-TV regularization for the functions is of the class H\"older continuous. Over some compact and convex domain \Omega, we study construction of multivariate function \varphi(\mathbf{x}) :\Omega \subset \mathbb{R}^{3} \rightarrow \mathbb{R}_{+} as the optimized solution to the following convex minimization problem   \begin{equation} \min_{\Omega} \left\{F_{\alpha}(\cdot, f^{\delta}) := \frac{1}{2} \Vert \mathcal{T}(\cdot) - f^{\delta} \Vert_{\mathcal{H}}^2 + \alpha J(\cdot) \right\}, \end{equation} where the penalizer J(\cdot) : \mathcal{C}^{1}(\Omega,\mathbb{R}^{3})\rightarrow \mathbb{R}_{+} is the smoothed total variation penalizer   \begin{equation} J(\cdot) = \int_{\Omega} \sqrt{\Vert\nabla(\cdot)\Vert_2^2 + \beta} d \mathbf{x}, \end{equation} for a fixed 0 < \beta < 1. We assume our target function to be H\"older continuous. With this assumption, we establish relation between total variation of our target function and its H\"older coefficient. We prove that the smoothed-TV regularization is an admissible regularization strategy by evaluating the discrepancy \Vert\mathcal{T}\varphi_{\alpha} - f^{\delta}\Vert \leq \tau\delta, for some fixed \tau \geq 1. To do so, we need to assume that the target function to be class of \mathcal{C}^{1+}(\Omega). From here, under the fact that the penalty J(\cdot) is strongly convex, we move on to showing the convergence of \Vert\varphi_{\alpha} - \varphi^{\dagger}\Vert, for \varphi_{\alpha} is the optimum and \varphi^{\dagger} is the true solution for the given minimization problem above. We demonstrate that strong convexity and 2-convexity are actually different names for the same concept. In addition to these facts, we make us of Bregman divergence in order to be able to quantify the rate of convergence.