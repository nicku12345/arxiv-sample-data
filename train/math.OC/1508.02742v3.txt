We introduce a mixed {\em generalized} Dynkin game/stochastic control with {\cal E}^f-expectation in a Markovian framework. We study both the case when the terminal reward function is supposed to be Borelian only and when it is continuous. We first establish a weak dynamic programming principle by using some refined results recently provided in \cite{DQS} and some properties of doubly reflected BSDEs with jumps (DRBSDEs). We then show a stronger dynamic programming principle in the continuous case, which cannot be derived from the weak one. In particular, we have to prove that the value function of the problem is continuous with respect to time t, which requires some technical tools of stochastic analysis and some new results on DRBSDEs. We finally study the links between our mixed problem and generalized Hamilton Jacobi Bellman variational inequalities in both cases.