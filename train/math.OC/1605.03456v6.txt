Extended real-valued functions are often used in optimization theory, but in different ways for infimum problems and for supremum problems. We present an approach to extended real-valued functions that works for all types of problems and into which results of convex analysis can be embedded. Our approach preserves continuity and the Chebyshev norm when extending a functional to the entire space. The basic idea also works for other image spaces. Moreover, we illustrate that extended real-valued functions have to be handled in another way than real-valued functions and characterize semicontinuity, convexity, linearity and related properties of such functions.