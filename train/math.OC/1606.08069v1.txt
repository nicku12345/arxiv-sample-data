Existing implementations of gradient-based optimisation methods typically assume that the problem is posed in Euclidean space. When solving optimality problems on function spaces, the functional derivative is then inaccurately represented with respect to \ell^2 instead of the inner product induced by the function space. This error manifests as a mesh dependence in the number of iterations required to solve the optimisation problem. In this paper, an analytic estimate is derived for this iteration count in the case of a simple and generic discretised optimisation problem. The system analysed is the steepest descent method applied to a finite element problem. The estimate is based on Kantorovich's inequality and on an upper bound for the condition number of Galerkin mass matrices. Computer simulations validate the iteration number estimate. Similar numerical results are found for a more complex optimisation problem constrained by a partial differential equation. Representing the functional derivative with respect to the inner product induced by the continuous control space leads to mesh independent convergence.