This paper studies a distributed stochastic optimization problem over random networks with imperfect communications subject to a global constraint, which is the intersection of local constraint sets assigned to agents. The global cost function is the sum of local cost functions, each of which is the expectation of a random cost function. By incorporating the augmented Lagrange technique with the projection method, a stochastic approximation based distributed primal-dual algorithm is proposed to solve the problem. Each agent updates its estimate by using the local observations and the information derived from neighbors. For the constrained problem, the estimates are first shown to be bounded almost surely (a.s.), and then are proved to converge to the optimal solution set a.s. Furthermore, the asymptotic normality and efficiency of the algorithm are addressed for the unconstrained case. The results demonstrate the influence of random networks, communication noises, and gradient errors on the performance of the algorithm. Finally, numerical simulations demonstrate the theoretic results.