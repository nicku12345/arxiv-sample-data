Black-box optimization of objective function of parameters belonging to simplex arises in many inference and predictive models. Das (2016) introduced Greedy Co-ordinate Descent of Varying Step-sizes on Simplex (GCDVSS) which efficiently optimizes any black-box function whose parameters belong to a simplex. In this paper, that method has been modified and extended for the case where the set of parameters may belong to multiple simplex block of different sizes. The main principle of this algorithm is to make jumps of varying step-sizes within each simplexes simultaneously and searching for the best direction for movement. Since this algorithm is designed specially for multiple simplex blocks parameter space, the proportion of movements made within the parameter space during the update step of a iteration is relatively higher for the proposed algorithm. Starting from a single initial guess, unlike genetic algorithm or simulated annealing, requirement of parallelization for this algorithm grows linearly with the dimension of the parameter space which makes it more efficient for higher dimensional optimization problems. Comparative studies with some existing algorithms have been provided based on modified well-known benchmark functions. Upto 7 folds of improvement in computation time has been noted for using the proposed algorithm over Genetic algorithm, yielding significantly better solution in all the cases considered.