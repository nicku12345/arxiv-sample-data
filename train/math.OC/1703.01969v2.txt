This paper introduces an efficient first-order method based on the alternating direction method of multipliers (ADMM) to solve semidefinite programs (SDPs) arising from sum-of-squares (SOS) programming. We exploit the sparsity of the \emph{coefficient matching conditions} when SOS programs are formulated in the usual monomial basis to reduce the computational cost of the ADMM algorithm. Each iteration of our algorithm requires one projection onto the positive semidefinite cone and the solution of multiple quadratic programs with closed-form solutions free of any matrix inversion. Our techniques are implemented in the open-source MATLAB solver SOSADMM. Numerical experiments on SOS problems arising from unconstrained polynomial minimization and from Lyapunov stability analysis for polynomial systems show speed-ups compared to the interior-point solver SeDuMi, and the first-order solver CDCS.