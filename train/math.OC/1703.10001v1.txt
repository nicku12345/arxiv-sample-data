In this article, two methods for solving mean-field type optimal control problems are proposed and investigated. The two methods are iterative methods: at each iteration, a Hamilton-Jacobi-Bellman equation is solved, for a terminal condition obtained by linearizing the cost function. The terminal condition is updated by solving a Fokker-Planck equation. The first method can be seen as a gradient method and uses in an essential manner the convexity of the set of probability distributions. A convergence result for this method is provided. The second method incorporates a penalization term and provides feedback controls. We test the methods on four academic examples.