Newton's method for finding an unconstrained minimizer for strictly convex functions, generally speaking, does not converge from any starting point.   We introduce and study the damped regularized Newton's method (DRNM). It converges globally for any strictly convex function, which has a minimizer in R^n.   Locally DRNM converges with a quadratic rate. We characterize the neighborhood of the minimizer, where the quadratic rate occurs. Based on it we estimate the number of DRNM's steps required for finding an \varepsilon- approximation for the minimizer.