The paper is devoted to dynamic games. We consider a general enough framework, which is not limited to e.g. differential games and could accommodate both discrete and continuous time. Assuming common dynamics, we study two game families with total payoffs that are defined either as the Ces\`{a}ro average (long run average game family) or Abel average (discounting game family) of the running costs. We study a robust strategy that would provide a near-optimal total payoff for all sufficiently small discounts and for all sufficiently large planning horizons. Assuming merely the Dynamic Programming Principle, we prove the following Tauberian theorem: if a strategy is uniformly optimal for one of the families (when discount goes to zero for discounting games, when planning horizon goes to infinity in long run average games) and its value functions converge uniformly, then, for the other family, this strategy is also uniformly optimal and its value functions converge uniformly to the same limit.