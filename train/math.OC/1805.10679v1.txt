The paper is devoted to new modifications of recently proposed adaptive methods of Mirror Descent for convex minimization problems in the case of several convex functional constraints. Methods for problems of two classes are considered. The first type of problems with Lipschitz-continuous objective (generally speaking, nonsmooth) functional. The second one is for problems with a Lipschitz-continuous gradient of the objective smooth functional. We consider the class of problems with a non-smooth objective functional equal to the maximum of smooth functionals with a Lipschitz-continuous gradient. Note that functional constraints, generally speaking, are non-smooth and Lipschitz-contionuous. The proposed modifications allow saving the algorithm running time due to consideration of not all functional constraints on non-productive steps. Estimates for the rate of convergence of the methods under consideration are obtained. The methods proposed are optimal from the point of view of lower oracle estimates. The results of numerical experiments illustrating the advantages of the proposed procedure for some examples are given.