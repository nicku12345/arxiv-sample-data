Self-normalized processes arise naturally in statistical applications.   Being unit free, they are not affected by scale changes. Moreover, self-normalization often eliminates or weakens moment assumptions. In this paper we present several exponential and moment inequalities, particularly those related to laws of the iterated logarithm, for self-normalized random variables including martingales. Tail probability bounds are also derived. For random variables B_t>0 and A_t, let Y_t(\lambda)=\exp{\lambda A_t-\lambda ^2B_t^2/2}. We develop inequalities for the moments of A_t/B_{t} or sup_{t\geq 0}A_t/{B_t(\log \log B_{t})^{1/2}} and variants thereof, when EY_t(\lambda )\leq 1 or when Y_t(\lambda) is a supermartingale, for all \lambda belonging to some interval. Our results are valid for a wide class of random processes including continuous martingales with A_t=M_t and B_t=\sqrt < M>_t, and sums of conditionally symmetric variables d_i with A_t=\sum_{i=1}^td_i and B_t=\sqrt\sum_{i=1}^td_i^2. A sharp maximal inequality for conditionally symmetric random variables and for continuous local martingales with values in R^m, m\ge 1, is also established. Another development in this paper is a bounded law of the iterated logarithm for general adapted sequences that are centered at certain truncated conditional expectations and self-normalized by the square root of the sum of squares. The key ingredient in this development is a new exponential supermartingale involving \sum_{i=1}^td_i and \sum_{i=1}^td_i^2.