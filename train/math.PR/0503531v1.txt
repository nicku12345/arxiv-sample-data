We study pathwise approximation of scalar stochastic differential equations at a single point. We provide the exact rate of convergence of the minimal errors that can be achieved by arbitrary numerical methods that are based (in a measurable way) on a finite number of sequential observations of the driving Brownian motion. The resulting lower error bounds hold in particular for all methods that are implementable on a computer and use a random number generator to simulate the driving Brownian motion at finitely many points. Our analysis shows that approximation at a single point is strongly connected to an integration problem for the driving Brownian motion with a random weight. Exploiting general ideas from estimation of weighted integrals of stochastic processes, we introduce an adaptive scheme, which is easy to implement and performs asymptotically optimally.