Let S be a denumerable state space and let P be a transition probability matrix on S. If a denumerable set M of nonnegative matrices is such that the sum of the matrices is equal to P, then we call M a partition of P. Let K denote the set of probability vectors on S. To every partition M of P we can associate a transition probability function on K defined in such a way that if p in K and m in M are such that ||pm|| > 0, then, with probability ||pm|| the vector p is transferred to the vector pm/||pm||. Here ||.|| denotes the l_1-norm. In this paper we investigate convergence in distribution for Markov chains generated by transition probability functions induced by partitions of transition probability matrices. An important application of the convergence results obtained is to filtering processes of partially observed Markov chains.