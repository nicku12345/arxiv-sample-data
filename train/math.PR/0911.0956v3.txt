We study a stochastic control problem on a bounded domain, which arises from a continuous-time optimal management model. Via the corresponding Hamilton-Jacobi-Bellman equation the value function is shown to be jointly continuous and to satisfy the Dynamic Programming Principle. These properties directly lead to the conclusion that the value function is a viscosity solution to the Hamilton-Jacobi-Bellman equation. Uniqueness of the solution is then also established.