For a matrix {\bf A} with linearly independent columns, this work studies to use its normalization \bar{\bf A} and {\bf A} itself to approximate its orthonormalization \bf V. We theoretically analyze the order of the approximation errors as \bf A and \bar{\bf A} approach {\bf V}, respectively. Our conclusion is able to explain the fact that a high dimensional Gaussian matrix can well approximate the corresponding truncated Haar matrix. For applications, this work can serve as a foundation of a wide variety of problems in signal processing such as compressed subspace clustering.