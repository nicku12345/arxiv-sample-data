The Rayleigh-Ritz method is widely used for eigenvalue approximation. Given a matrix X with columns that form an orthonormal basis for a subspace \X, and a Hermitian matrix A, the eigenvalues of X^HAX are called Ritz values of A with respect to \X. If the subspace \X is A-invariant then the Ritz values are some of the eigenvalues of A. If the A-invariant subspace \X is perturbed to give rise to another subspace \Y, then the vector of absolute values of changes in Ritz values of A represents the absolute eigenvalue approximation error using \Y. We bound the error in terms of principal angles between \X and \Y. We capitalize on ideas from a recent paper [DOI: 10.1137/060649070] by A. Knyazev and M. Argentati, where the vector of absolute values of differences between Ritz values for subspaces \X and \Y was weakly (sub-)majorized by a constant times the sine of the vector of principal angles between \X and \Y, the constant being the spread of the spectrum of A. In that result no assumption was made on either subspace being A-invariant. It was conjectured there that if one of the trial subspaces is A-invariant then an analogous weak majorization bound should only involve terms of the order of sine squared. Here we confirm this conjecture. Specifically we prove that the absolute eigenvalue error is weakly majorized by a constant times the sine squared of the vector of principal angles between the subspaces \X and \Y, where the constant is proportional to the spread of the spectrum of A. For many practical cases we show that the proportionality factor is simply one, and that this bound is sharp. For the general case we can only prove the result with a slightly larger constant, which we believe is artificial.