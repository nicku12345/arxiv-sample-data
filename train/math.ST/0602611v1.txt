In this study, we introduce a new approach to statistical decision theory. Without using a loss function, we select good decision rules to choice between two hypotheses. We call them "experts". They are globally unbiased but also conditionally unbiased on a family of events. We do not try to define the best expert. We define a probability distribution on the space of "experts". The measure of evidence for a hypothesis is the inductive probability of experts that decide this hypothesis, we call this measure: a "vote". We compare this point of view with the p-values. For some family of hypotheses, the "votes" can define a probability on the space of parameters. We compare these results with the Bayes posterior distributions. We study in detail real-parameter families of distributions with monotone likelihood ratio and multiparameter exponential families.