In the analysis of microarray data, and in some other contemporary statistical problems, it is not uncommon to apply hypothesis tests in a highly simultaneous way. The number, \nu say, of tests used can be much larger than the sample sizes, n, to which the tests are applied, yet we wish to calibrate the tests so that the overall level of the simultaneous test is accurate. Often the sampling distribution is quite different for each test, so there may not be an opportunity for combining data across samples. In this setting, how large can \nu be, as a function of n, before level accuracy becomes poor? In the present paper we answer this question in cases where the statistic under test is of Student's t type. We show that if either Normal or Student's t distribution is used for calibration then the level of the simultaneous test is accurate provided \log\nu increases at a strictly slower rate than n^{1/3} as n diverges. On the other hand, if bootstrap methods are used for calibration then we may choose \log\nu almost as large as n\half and still achieve asymptotic level accuracy.   The implications of these results are explored both theoretically and numerically.