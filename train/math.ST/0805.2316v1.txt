We consider a test for the hypothesis that the within-treatment variance component in a one-way random effects model is null. This test is based on a decomposition of a U-statistic. Its asymptotic null distribution is derived under the mild regularity condition that the second moment of the random effects and the fourth moment of the within-treatment errors are finite. Under the additional assumption that the fourth moment of the random effect is finite, we also derive the distribution of the proposed U-test statistic under a sequence of local alternative hypotheses. We report the results of a simulation study conducted to compare the performance of the U-test with that of the usual F-test. The main conclusions of the simulation study are that (i) under normality or under moderate degrees of imbalance in the design, the F-test behaves well when compared to the U-test, and (ii) when the distribution of the random effects and within-treatment errors are nonnormal, the U-test is preferable even when the number of treatments is small.