This paper offers a new approach to modeling and forecasting of nonstationary time series with applications to volatility modeling for financial data. The approach is based on the assumption of local homogeneity: for every time point, there exists a historical interval of homogeneity, in which the volatility parameter can be well approximated by a constant. The proposed procedure recovers this interval from the data using the local change point (LCP) analysis. Afterward, the estimate of the volatility can be simply obtained by local averaging. The approach carefully addresses the question of choosing the tuning parameters of the procedure using the so-called ``propagation'' condition. The main result claims a new ``oracle'' inequality in terms of the modeling bias which measures the quality of the local constant approximation. This result yields the optimal rate of estimation for smooth and piecewise constant volatility functions. Then, the new procedure is applied to some data sets and a comparison with a standard GARCH model is also provided. Finally, we discuss applications of the new method to the Value at Risk problem. The numerical results demonstrate a very reasonable performance of the new method.