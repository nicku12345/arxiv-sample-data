We present new estimators of the mean of a real valued random variable, based on PAC-Bayesian iterative truncation. We analyze the non-asymptotic minimax properties of the deviations of estimators for distributions having either a bounded variance or a bounded kurtosis. It turns out that these minimax deviations are of the same order as the deviations of the empirical mean estimator of a Gaussian distribution. Nevertheless, the empirical mean itself performs poorly at high confidence levels for the worst distribution with a given variance or kurtosis (which turns out to be heavy tailed). To obtain (nearly) minimax deviations in these broad class of distributions, it is necessary to use some more robust estimator, and we describe an iterated truncation scheme whose deviations are close to minimax. In order to calibrate the truncation and obtain explicit confidence intervals, it is necessary to dispose of a prior bound either on the variance or the kurtosis. When a prior bound on the kurtosis is available, we obtain as a by-product a new variance estimator with good large deviation properties. When no prior bound is available, it is still possible to use Lepski's approach to adapt to the unknown variance, although it is no more possible to obtain observable confidence intervals.