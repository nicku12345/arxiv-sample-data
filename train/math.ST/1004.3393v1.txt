We present optimality results for robust Kalman filtering where robustness is understood in a distributional sense, i.e.; we enlarge the distribution assumptions made in the ideal model by suitable neighborhoods. This allows for outliers which in our context may be system-endogenous or -exogenous, which induces the somewhat conflicting goals of tracking and attenuation. The corresponding minimax MSE-problems are solved for both types of outliers separately, resulting in closed-form saddle-points which consist of an optimally-robust procedure and a corresponding least favorable outlier situation. The results are valid in a surprisingly general setup of state space models, which is not limited to a Euclidean or time-discrete framework. The solution however involves computation of conditional means in the ideal model, which may pose computational problems. In the particular situation that the ideal conditional mean is linear in the observation innovation, we come up with a straight-forward Huberization, the rLS filter, which is very easy to compute. For this linearity we obtain an again surprising characterization.