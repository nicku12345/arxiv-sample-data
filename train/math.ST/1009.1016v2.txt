We address the problem of density estimation with \mathbb{L}_s-loss by selection of kernel estimators. We develop a selection procedure and derive corresponding \mathbb{L}_s-risk oracle inequalities. It is shown that the proposed selection rule leads to the estimator being minimax adaptive over a scale of the anisotropic Nikol'skii classes. The main technical tools used in our derivations are uniform bounds on the \mathbb{L}_s-norms of empirical processes developed recently by Goldenshluger and Lepski [Ann. Probab. (2011), to appear].