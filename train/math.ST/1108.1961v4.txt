Given a dictionary of M_n initial estimates of the unknown true regression function, we aim to construct linearly aggregated estimators that target the best performance among all the linear combinations under a sparse q-norm (0 \leq q \leq 1) constraint on the linear coefficients. Besides identifying the optimal rates of aggregation for these \ell_q-aggregation problems, our multi-directional (or universal) aggregation strategies by model mixing or model selection achieve the optimal rates simultaneously over the full range of 0\leq q \leq 1 for general M_n and upper bound t_n of the q-norm. Both random and fixed designs, with known or unknown error variance, are handled, and the \ell_q-aggregations examined in this work cover major types of aggregation problems previously studied in the literature. Consequences on minimax-rate adaptive regression under \ell_q-constrained true coefficients (0 \leq q \leq 1) are also provided.   Our results show that the minimax rate of \ell_q-aggregation (0 \leq q \leq 1) is basically determined by an effective model size, which is a sparsity index that depends on q, t_n, M_n, and the sample size n in an easily interpretable way based on a classical model selection theory that deals with a large number of models. In addition, in the fixed design case, the model selection approach is seen to yield optimal rates of convergence not only in expectation but also with exponential decay of deviation probability. In contrast, the model mixing approach can have leading constant one in front of the target risk in the oracle inequality while not offering optimality in deviation probability.