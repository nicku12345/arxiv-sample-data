We observe a N\times M matrix Y_{ij}=s_{ij}+\xi_{ij} with \xi_{ij}\sim {\mathcal {N}}(0,1) i.i.d. in i,j, and s_{ij}\in \mathbb {R}. We test the null hypothesis s_{ij}=0 for all i,j against the alternative that there exists some submatrix of size n\times m with significant elements in the sense that s_{ij}\ge a>0. We propose a test procedure and compute the asymptotical detection boundary a so that the maximal testing risk tends to 0 as M\to\infty, N\to\infty, p=n/N\to0, q=m/M\to0. We prove that this boundary is asymptotically sharp minimax under some additional constraints. Relations with other testing problems are discussed. We propose a testing procedure which adapts to unknown (n,m) within some given set and compute the adaptive sharp rates. The implementation of our test procedure on synthetic data shows excellent behavior for sparse, not necessarily squared matrices. We extend our sharp minimax results in different directions: first, to Gaussian matrices with unknown variance, next, to matrices of random variables having a distribution from an exponential family (non-Gaussian) and, finally, to a two-sided alternative for matrices with Gaussian elements.