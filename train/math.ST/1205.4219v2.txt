This paper considers testing a covariance matrix \Sigma in the high dimensional setting where the dimension p can be comparable or much larger than the sample size n. The problem of testing the hypothesis H_0:\Sigma=\Sigma_0 for a given covariance matrix \Sigma_0 is studied from a minimax point of view. We first characterize the boundary that separates the testable region from the non-testable region by the Frobenius norm when the ratio between the dimension p over the sample size n is bounded. A test based on a U-statistic is introduced and is shown to be rate optimal over this asymptotic regime. Furthermore, it is shown that the power of this test uniformly dominates that of the corrected likelihood ratio test (CLRT) over the entire asymptotic regime under which the CLRT is applicable. The power of the U-statistic based test is also analyzed when p/n is unbounded.