This paper introduces a new framework to study the asymptotical behavior of the empirical distribution function (e.d.f.) of Gaussian vector components, whose correlation matrix \Gamma^{(m)} is dimension-dependent. Hence, by contrast with the existing literature, the vector is not assumed to be stationary. Rather, we make a "vanishing second order" assumption ensuring that the covariance matrix \Gamma^{(m)} is not too far from the identity matrix, while the behavior of the e.d.f. is affected by \Gamma^{(m)} only through the sequence \gamma_m=m^{-2} \sum_{i\neq j} \Gamma_{i,j}^{(m)}, as m grows to infinity. This result recovers some of the previous results for stationary long-range dependencies while it also applies to various, high-dimensional, non-stationary frameworks, for which the most correlated variables are not necessarily next to each other. Finally, we present an application of this work to the multiple testing problem, which was the initial statistical motivation for developing such a methodology.