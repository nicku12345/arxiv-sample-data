We consider testing for presence of a signal in Gaussian white noise with intensity 1/sqrt(n), when the alternatives are given by smoothness ellipsoids with an L2-ball of (squared) radius rho removed. It is known that, for a fixed Sobolev type ellipsoid of smoothness beta and size M, a rho which is of order n to the power -4 beta/(4 beta+1)} is the critical separation rate, in the sense that the minimax error of second kind over alpha-tests stays asymptotically between 0 and 1 strictly (Ingster, 1982). In addition, Ermakov (1990) found the sharp asymptotics of the minimax error of second kind at the separation rate. For adaptation over both beta and M in that context, it is known that a loglog-penalty over the separation rate for rho is necessary for a nonzero asymptotic power. Here, following an example in nonparametric estimation related to the Pinsker constant, we investigate the adaptation problem over the ellipsoid size M only, for fixed smoothness degree beta. It is established that the sharp risk asymptotics can be replicated in that adaptive setting, if rho tends to zero slower than the separation rate. The penalty for adaptation here turns out to be a sequence tending to infinity arbitrarily slowly.