Functional principal components (FPC's) provide the most important and most extensively used tool for dimension reduction and inference for functional data. The selection of the number, d, of the FPC's to be used in a specific procedure has attracted a fair amount of attention, and a number of reasonably effective approaches exist. Intuitively, they assume that the functional data can be sufficiently well approximated by a projection onto a finite-dimensional subspace, and the error resulting from such an approximation does not impact the conclusions. This has been shown to be a very effective approach, but it is desirable to understand the behavior of many inferential procedures by considering the projections on subspaces spanned by an increasing number of the FPC's. Such an approach reflects more fully the infinite-dimensional nature of functional data, and allows to derive procedures which are fairly insensitive to the selection of d. This is accomplished by considering limits as d tends to infinity with the sample size.   We propose a specific framework in which we let d tend to infinity by deriving a normal approximation for the two-parameter partial sum process of the scores \xi_{i,j} of the i-th function with respect to the j-th FPC. Our approximation can be used to derive statistics that use segments of observations and segments of the FPC's. We apply our general results to derive two inferential procedures for the mean function: a change-point test and a two-sample test. In addition to the asymptotic theory, the tests are assessed through a small simulation study and a data example.