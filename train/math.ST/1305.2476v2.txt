In this paper we show how to use Fourier transform methods to analyze the asymptotic behavior of kernel distribution function estimators. Exact expressions for the mean integrated squared error in terms of the characteristic function of the distribution and the Fourier transform of the kernel are employed to obtain the limit value of the optimal bandwidth sequence in its greatest generality. The assumptions in our results are mild enough so that they are applicable when the kernel used in the estimator is a superkernel, or even the sinc kernel, and this allows to extract some interesting consequences, as the existence of a class of distributions for which the kernel estimator achieves a first-order improvement in efficiency over the empirical distribution function.