We consider Grenander type estimators for monotone functions f in a very general setting, which includes estimation of monotone regression curves, monotone densities, and monotone failure rates. These estimators are defined as the left-hand slope of the least concave majorant \hat{F}_n of a naive estimator F_n of the integrated curve F corresponding to f. We prove that the supremum distance between \hat{F}_n and F_n is of the order O_p(n^{-1}\log n)^{2/(4-\tau)}, for some \tau\in[0,4) that characterizes the tail probabilities of an approximating process for F_n. In typical examples, the approximating process is Gaussian and \tau=1, in which case the convergence rate is n^{-2/3}(\log n)^{2/3} is in the same spirit as the one obtained by Kiefer and Wolfowitz (1976) for the special case of estimating a decreasing density. We also obtain a similar result for the primitive of F_n, in which case \tau=2, leading to a faster rate n^{-1}\log n, also found by Wang and Woodfroofe (2007). As an application in our general setup, we show that a smoothed Grenander type estimator and its derivative are asymptotically equivalent to the ordinary kernel estimator and its derivative in first order.