Statistical inference based on moment conditions and estimating equations is of substantial interest when it is difficult to specify a full probabilistic model. We propose a Bayesian flavored model selection framework based on (quasi-)posterior probabilities from the Bayesian Generalized Method of Moments (BGMM), which allows us to incorporate two important advantages of a Bayesian approach: the expressiveness of posterior distributions and the convenient computational method of Markov Chain Monte Carlo (MCMC). Theoretically we show that BGMM can achieve the posterior consistency for selecting the unknown true model, and that it possesses a Bayesian version of the oracle property, i.e. the posterior distribution for the parameter of interest is asymptotically normal and is as informative as if the true model were known. In addition, we show that the proposed quasi-posterior is valid to be interpreted as an approximate posterior distribution given a data summary. Our applications include modeling of correlated data, quantile regression, and graphical models based on partial correlations. We demonstrate the implementation of the BGMM model selection through numerical examples.