We provide new theoretical results in the field of inverse regression methods for dimension reduction. Our approach is based on the study of some empirical processes that lie close to a certain dimension reduction subspace, called the central subspace. The study of these processes essentially includes weak convergence results and the consistency of some general bootstrap procedures. While such properties are used to obtain new results about sliced inverse regression, they mainly allow to define a natural family of methods for dimension reduction. First the estimation methods are shown to have root n rates and the bootstrap is proved to be valid. Second, we describe a family of Cram\'er-von Mises test statistics that can be used in testing structural properties of the central subspace or the significancy of some sets of predictors. We show that the quantiles of those tests could be computed by bootstrap. Most of the existing methods related to inverse regression involve a slicing of the response that is difficult to select in practice. While our approach guarantee a comprehensive estimation, the slicing is no longer needed.