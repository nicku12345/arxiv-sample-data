Given an i.i.d. sample \{(X_i,Y_i)\}_{i \in \{1 \ldots n\}} from the random design regression model Y = f(X) + \epsilon with (X,Y) \in [0,1] \times [-M,M], in this paper we consider the problem of testing the (simple) null hypothesis f = f_0, against the alternative f \neq f_0 for a fixed f_0 \in L^2([0,1],G_X), where G_X(\cdot) denotes the marginal distribution of the design variable X. The procedure proposed is an adaptation to the regression setting of a multiple testing technique introduced by Fromont and Laurent (2005), and it amounts to consider a suitable collection of unbiased estimators of the L^2--distance d_2(f,f_0) = \int {[f(x) - f_0 (x)]^2 d\,G_X (x)}, rejecting the null hypothesis when at least one of them is greater than its (1-u_\alpha) quantile, with u_\alpha calibrated to obtain a level--\alpha test. To build these estimators, we will use the warped wavelet basis introduced by Picard and Kerkyacharian (2004). We do not assume that the errors are normally distributed, and we do not assume that X and \epsilon are independent but, mainly for technical reasons, we will assume, as in most part of the current literature in learning theory, that |f(x) - y| is uniformly bounded (almost everywhere). We show that our test is adaptive over a particular collection of approximation spaces linked to the classical Besov spaces.