Let (X\_1,\ldots,X\_n) be a d-dimensional i.i.d sample from a distribution with density f. The problem of detection of a two-component mixture is considered. Our aim is to decide whether f is the density of a standard Gaussian random d-vector (f=\phi\_d) against f is a two-component mixture: f=(1-\varepsilon)\phi\_d +\varepsilon \phi\_d (.-\mu) where (\varepsilon,\mu) are unknown parameters. Optimal separation conditions on \varepsilon, \mu, n and the dimension d are established, allowing to separate both hypotheses with prescribed errors. Several testing procedures are proposed and two alternative subsets are considered.