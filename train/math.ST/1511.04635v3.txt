The likelihood function plays a pivotal role in statistical inference; it is adaptable to a wide range of models and the resultant estimators are known to have good properties. However, these results hinge on correct specification of the data generating mechanism. Many modern problems involve extremely complicated distribution functions, which may be difficult -- if not impossible -- to express explicitly. This is a serious barrier to the likelihood approach, which requires not only the specification of a distribution, but the correct distribution. Non-parametric methods are one way to avoid the problem of having to specify a particular data generating mechanism, but can be computationally intensive, reducing their accessibility for large data problems. We propose a new approach that combines multiple non-parametric likelihood-type components to build a data-driven approximation of the true function. The new construct builds on empirical and composite likelihood, taking advantage of the strengths of each. Specifically, from empirical likelihood we borrow the ability to avoid a parametric specification, and from composite likelihood we utilize multiple likelihood components. We will examine the theoretical properties of this composite empirical likelihood, both for purposes of application and to compare properties to other established likelihood methods.