We establish a general theory of optimality for block bootstrap distribution estimation for sample quantiles under a mild strong mixing assumption. In contrast to existing results, we study the block bootstrap for varying numbers of blocks. This corresponds to a hybrid between the subsampling bootstrap and the moving block bootstrap (MBB), in which the number of blocks is somewhere between 1 and the ratio of sample size to block length. Our main theorem determines the optimal choice of the number of blocks and block length to achieve the best possible convergence rate for the block bootstrap distribution estimator for sample quantiles. As part of our analysis, we also prove an important lemma which gives the convergence rate of the block bootstrap distribution estimator, with implications even for the smooth function model. We propose an intuitive procedure for empirical selection of the optimal number and length of blocks. Relevant examples are presented which illustrate the benefits of optimally choosing the number of blocks.