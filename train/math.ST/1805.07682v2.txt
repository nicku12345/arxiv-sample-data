We study uniqueness in the generalized lasso problem, where the penalty is the \ell_1 norm of a matrix D times the coefficient vector. We derive a broad result on uniqueness that places weak assumptions on the predictor matrix X and penalty matrix D; the implication is that, if D is fixed and its null space is not too large (the dimension of its null space is at most the number of samples), and X and response vector y jointly follow an absolutely continuous distribution, then the generalized lasso problem has a unique solution almost surely, regardless of the number of predictors relative to the number of samples. This effectively generalizes previous uniqueness results for the lasso problem (which corresponds to the special case D=I). Further, we extend our study to the case in which the loss is given by the negative log-likelihood from a generalized linear model. In addition to uniqueness results, we derive results on the local stability of generalized lasso solutions that might be of interest in their own right.