Divergence functions are interesting discrepancy measures. Even though they are not true distances, we can use them to measure how separated two points are. Curiously enough, when they are applied to random variables, they lead to a notion of best predictor that coincides with usual best predictor in Euclidean distance. Given a divergence function, we can derive from it a Riemannian metric, which leads to a distance in which means and best predictors do not coincide with their Euclidean counterparts. It is the purpose of this note to study the Riemannian metric derived from the divergence function as well as its use in prediction theory.